import streamlit as st
from database.db_operations import Database
from utils.ml_utils import MODELS, MODELS_ZIP, classify_document, load_model, AnomalyAwareClassifier
from utils.file_utils import extract_text_from_file
import plotly.express as px
import pandas as pd
import os
import io
import zipfile
import tempfile
import shutil


db = Database()

# –õ–∏—á–Ω—ã–π –∫–∞–±–∏–Ω–µ—Ç –∫–ª–∏–µ–Ω—Ç–∞
def client_page(user, vectorizer):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
    if not user:
        st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–æ–π–¥–∏—Ç–µ –≤ —Å–∏—Å—Ç–µ–º—É –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ.")
        st.stop()

    st.title(f"–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å, {user['login']}")

    # –ö–Ω–æ–ø–∫–∞ –≤—ã—Ö–æ–¥–∞
    if st.button("–í—ã–π—Ç–∏"):
        st.session_state.user = None
        st.rerun()

    # –§—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
    def translate_class(pred, model):
        # –î–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        if model == "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è":
            cluster_names = {
                0: "–ü—Ä–∏–∫–∞–∑",
                1: "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ", 
                2: "–ü–∏—Å—å–º–æ",
                3: "–û–±—â–µ–µ"
            }
            return cluster_names.get(pred, f"–ö–ª–∞—Å—Ç–µ—Ä {pred}")
        
        # –î–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π
        class_map = {
            "Order": "–ü—Ä–∏–∫–∞–∑",
            "Ordinance": "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
            "Letters": "–ü–∏—Å—å–º–æ",
            "Miscellaneous": "–û–±—â–µ–µ"
        }
        return class_map.get(pred, pred)

    # –°–µ–∫—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    st.markdown("### üìÑ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    model_name = st.selectbox("üß† –ú–æ–¥–µ–ª—å", list(MODELS.keys()), key="client_model",
                            on_change=lambda: st.session_state.pop("last_classification_id", None))
    uploaded_file = st.file_uploader("üìé –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª", type=["txt", "pdf", "docx"], key="client_upload")

    # –ö–Ω–æ–ø–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    if uploaded_file and st.button(
        "üöÄ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å",
        key="client_classify",
        use_container_width=True
    ):
        with st.spinner("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç..."):
            try:
                prediction, confidence, preview, wc, lang = classify_document(uploaded_file, model_name, vectorizer)
                
                if prediction is not None:
                    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
                    russian_class = translate_class(prediction, model_name)
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
                    if model_name == "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è":
                        msg = f"‚úÖ –ö–ª–∞—Å—Å: **{russian_class}**"
                    else:
                        confidence_str = f"{confidence:.2%}" if confidence is not None else "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞"
                        msg = f"‚úÖ –ö–ª–∞—Å—Å: **{russian_class}** (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: **{confidence_str}**)"
                    
                    st.success(msg)
                    st.caption(f"üåê –Ø–∑—ã–∫: **{lang}** | üìè –°–ª–æ–≤: **{wc}**")
                    
                    with st.expander("üìÑ –ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ç–µ–∫—Å—Ç"):
                        st.text(preview[:5000] + "..." if len(preview) > 5000 else preview)
                        
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î (—Ä—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π)
                    classification_id = db.create_classification(
                        user["id"],
                        uploaded_file.name,
                        model_name,
                        russian_class,
                        float(confidence) if confidence is not None else None
                    )
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º ID –¥–ª—è –æ—Ü–µ–Ω–∫–∏
                    if classification_id:
                        st.session_state.last_classification_id = classification_id
                        st.session_state.show_rating = True
                else:
                    st.error("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç")
                    
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}")

    # –§–æ—Ä–º–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    if st.session_state.get("show_rating") and "last_classification_id" in st.session_state:
        with st.form("rating_form"):
            st.subheader("–û—Ü–µ–Ω–∏—Ç–µ —Ç–æ—á–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            rating = st.slider("–û—Ü–µ–Ω–∫–∞", 1, 5, 3, key="rating_slider")
            comment = st.text_area("–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)", key="rating_comment")
            
            if st.form_submit_button("üì§ –û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ü–µ–Ω–∫—É"):
                try:
                    if db.create_rating(
                        st.session_state.last_classification_id,
                        user["id"],
                        rating,
                        comment
                    ):
                        st.session_state.rating_submitted = True
                        st.session_state.pop("last_classification_id", None)
                        st.session_state.pop("show_rating", None)
                        st.rerun()
                    else:
                        st.error("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ü–µ–Ω–∫—É")
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ü–µ–Ω–∫–∏: {str(e)}")

    # –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± —É—Å–ø–µ—à–Ω–æ–π –æ—Ü–µ–Ω–∫–µ
    if st.session_state.get("rating_submitted", False):
        st.success("‚úÖ –°–ø–∞—Å–∏–±–æ –∑–∞ –≤–∞—à—É –æ—Ü–µ–Ω–∫—É! –í–∞—à –æ—Ç–∑—ã–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω.")
        st.session_state.pop("rating_submitted", None)


    st.markdown("---")

    # –°–µ–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—Ä—Ö–∏–≤–æ–≤
    st.markdown("### üóÇ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∞—Ä—Ö–∏–≤–∞ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ `.zip` —Ñ–∞–π–ª —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ (txt, pdf, docx), –∏ –ø–æ–ª—É—á–∏—Ç–µ –∞—Ä—Ö–∏–≤, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ –ø–∞–ø–∫–∞–º-–∫–ª–∞—Å—Å–∞–º.")

    zip_model = st.selectbox("üß† –ú–æ–¥–µ–ª—å –¥–ª—è –∞—Ä—Ö–∏–≤–∞", list(MODELS_ZIP.keys()), key="zip_model")
    zip_file = st.file_uploader("üìé –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∞—Ä—Ö–∏–≤", type=["zip"], key="zip_upload")

    # –§—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤
    def translate_class_name(class_name):
        translation = {
            "Order": "–ü—Ä–∏–∫–∞–∑",
            "Ordinance": "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
            "Letters": "–ü–∏—Å—å–º–æ",
            "Miscellaneous": "–û–±—â–µ–µ"
        }
        return translation.get(class_name, class_name)

    if zip_file and st.button(
        "üìÇ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∞—Ä—Ö–∏–≤", 
        key="zip_classify",
        use_container_width=True
    ):
        with st.spinner("üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—Ä—Ö–∏–≤–∞..."):
            try:
                # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –æ–± –∞—Ä—Ö–∏–≤–µ
                zip_folder_id = db.create_zip_folder(
                    user["id"],
                    zip_file.name,
                    0
                )
                
                if not zip_folder_id:
                    st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∑–∞–ø–∏—Å—å –æ–± –∞—Ä—Ö–∏–≤–µ –≤ –ë–î")
                    return

                with tempfile.TemporaryDirectory() as tmpdir:
                    tmp_input = os.path.join(tmpdir, "input")
                    tmp_output = os.path.join(tmpdir, "output")
                    os.makedirs(tmp_input, exist_ok=True)
                    os.makedirs(tmp_output, exist_ok=True)

                    # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞
                    with zipfile.ZipFile(zip_file, "r") as zip_ref:
                        zip_ref.extractall(tmp_input)

                    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –∫–ª–∞—Å—Å–æ–≤ (—Å —Ä—É—Å—Å–∫–∏–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏)
                    class_dirs = {
                        "–ü–∏—Å—å–º–æ": os.path.join(tmp_output, "–ü–∏—Å—å–º–æ"),
                        "–ü—Ä–∏–∫–∞–∑": os.path.join(tmp_output, "–ü—Ä–∏–∫–∞–∑"),
                        "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ": os.path.join(tmp_output, "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ"),
                        "–û–±—â–µ–µ": os.path.join(tmp_output, "–û–±—â–µ–µ")
                    }
                    for path in class_dirs.values():
                        os.makedirs(path, exist_ok=True)

                    processed_files = 0
                    
                    for root, _, files in os.walk(tmp_input):
                        for fname in files:
                            file_path = os.path.join(root, fname)
                            ext = os.path.splitext(fname)[1].lower()
                            
                            if ext not in ['.txt', '.pdf', '.docx']:
                                continue
                            
                            try:
                                # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
                                if ext == '.txt':
                                    with open(file_path, 'r', encoding='utf-8') as f:
                                        text = f.read()
                                else:
                                    with open(file_path, 'rb') as f:
                                        file_content = f.read()
                                    
                                    class FileLikeObject(io.BytesIO):
                                        name = fname
                                        seekable = lambda self: True
                                        readable = lambda self: True
                                        writable = lambda self: False
                                        mode = 'rb'
                                        
                                        @property
                                        def type(self):
                                            return {
                                                '.pdf': 'application/pdf',
                                                '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
                                            }.get(ext, 'application/octet-stream')
                                    
                                    file_obj = FileLikeObject(file_content)
                                    text = extract_text_from_file(file_obj)

                                if not text or len(text.strip()) < 10:
                                    st.warning(f"‚ö†Ô∏è –§–∞–π–ª `{fname}` –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π.")
                                    continue
                                
                                # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
                                vector = vectorizer.transform([text])
                                model = load_model(zip_model)
                                pred = model.predict(vector)[0]
                                confidence = model.predict_proba(vector)[0].max() if hasattr(model, 'predict_proba') else None
                                
                                # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º
                                if zip_model == "Clustering":
                                    class_map = {
                                        0: "–ü—Ä–∏–∫–∞–∑",
                                        1: "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
                                        2: "–ü–∏—Å—å–º–æ",
                                        3: "–û–±—â–µ–µ"
                                    }
                                    russian_class = class_map.get(pred, "–û–±—â–µ–µ")
                                else:
                                    english_class = pred if isinstance(pred, str) else "Miscellaneous"
                                    russian_class = translate_class_name(english_class)
                                
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
                                classification_id = db.create_archive_classification(
                                    id_user=user["id"],
                                    filename=fname,
                                    model_name=zip_model,
                                    predicted_class=russian_class,
                                    confidence=float(confidence) if confidence is not None else None,
                                    id_folder_zip=zip_folder_id
                                )
                                
                                if not classification_id:
                                    continue
                                
                                # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –ø–∞–ø–∫—É
                                dst_dir = class_dirs.get(russian_class, class_dirs["–û–±—â–µ–µ"])
                                shutil.copy2(file_path, dst_dir)
                                processed_files += 1
                                
                            except Exception as e:
                                st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ `{fname}`: {str(e)}")

                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ —Ñ–∞–π–ª–æ–≤
                    if processed_files > 0:
                        db.update_zip_file_count(zip_folder_id, processed_files)

                    # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –∞—Ä—Ö–∏–≤
                    if processed_files > 0:
                        result_zip_path = os.path.join(tmpdir, "classified.zip")
                        with zipfile.ZipFile(result_zip_path, 'w') as zipf:
                            for class_name, class_dir in class_dirs.items():
                                if any(os.listdir(class_dir)):
                                    for root, _, files in os.walk(class_dir):
                                        for file in files:
                                            file_path = os.path.join(root, file)
                                            arcname = os.path.join(class_name, file)
                                            zipf.write(file_path, arcname)

                        with open(result_zip_path, "rb") as f:
                            st.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {processed_files}")
                            st.download_button(
                                "üì• –°–∫–∞—á–∞—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞—Ä—Ö–∏–≤",
                                f,
                                file_name="classified.zip",
                                mime="application/zip",
                                use_container_width=True
                            )
                    else:
                        st.error("‚ö†Ô∏è –ù–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª –Ω–µ –±—ã–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∞—Ä—Ö–∏–≤–∞.")

            except Exception as e:
                st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—Ä—Ö–∏–≤–∞: {str(e)}")


    # –°–µ–∫—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –æ–ø–µ—Ä–∞—Ü–∏–π
    st.markdown("---")
    st.subheader("üìã –ò—Å—Ç–æ—Ä–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π")

    def get_russian_class(eng_class):
        class_map = {
            "Order": "–ü—Ä–∏–∫–∞–∑",
            "Ordinance": "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
            "Letters": "–ü–∏—Å—å–º–æ",
            "Miscellaneous": "–û–±—â–µ–µ",
            0: "–ü—Ä–∏–∫–∞–∑",
            1: "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
            2: "–ü–∏—Å—å–º–æ",
            3: "–û–±—â–µ–µ",
        }
        return class_map.get(eng_class, eng_class)

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    history = db.get_user_history(user["id"])

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö
    if history is None or not isinstance(history, pd.DataFrame) or history.empty:
        st.info("–ò—Å—Ç–æ—Ä–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
        st.stop()

    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    history = history.rename(columns={
        'filename': '–î–æ–∫—É–º–µ–Ω—Ç',
        'model_used': '–ú–æ–¥–µ–ª—å',
        'predicted_class': '–ö–ª–∞—Å—Å',
        'confidence': '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å',
        'created_at': '–î–∞—Ç–∞',
        'rating': '–û—Ü–µ–Ω–∫–∞',
        'comment_user': '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π'
    })

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    history['–î–∞—Ç–∞'] = pd.to_datetime(history['–î–∞—Ç–∞'])
    min_date, max_date = history['–î–∞—Ç–∞'].min().date(), history['–î–∞—Ç–∞'].max().date()
    history['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] = history['–ö–ª–∞—Å—Å'].apply(get_russian_class)

    # === –§–ò–õ–¨–¢–†–´ ===
    with st.sidebar.expander("üîé –§–∏–ª—å—Ç—Ä—ã", expanded=True):
        st.markdown("### –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã")
        date_range = st.date_input("üìÖ –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç", [min_date, max_date], min_value=min_date, max_value=max_date)
        search_query = st.text_input("üîç –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é")
        
        categories = history['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].unique().tolist()
        selected_categories = st.multiselect("üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏", categories, default=categories)
        
        models = history['–ú–æ–¥–µ–ª—å'].unique().tolist()
        selected_models = st.multiselect("üß† –ú–æ–¥–µ–ª–∏", models, default=models)
        
        st.markdown("### –§–∏–ª—å—Ç—Ä—ã –æ—Ü–µ–Ω–æ–∫")
        min_rating, max_rating = st.slider(
            "‚≠ê –û—Ü–µ–Ω–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è", 
            min_value=1, 
            max_value=5, 
            value=(1, 5),
            step=1
        )
        show_only_rated = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å –æ—Ü–µ–Ω–∫–∞–º–∏", value=False)

    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
    if len(date_range) == 2:
        start_date = pd.to_datetime(date_range[0])
        end_date = pd.to_datetime(date_range[1]) + pd.Timedelta(days=1)
        history = history[(history['–î–∞—Ç–∞'] >= start_date) & (history['–î–∞—Ç–∞'] < end_date)]

    if search_query:
        history = history[history['–î–æ–∫—É–º–µ–Ω—Ç'].str.contains(search_query, case=False, na=False)]

    if selected_categories:
        history = history[history['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'].isin(selected_categories)]

    if selected_models:
        history = history[history['–ú–æ–¥–µ–ª—å'].isin(selected_models)]

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –æ—Ü–µ–Ω–∫–∞–º
    if show_only_rated:
        history = history[history['–û—Ü–µ–Ω–∫–∞'].notna()]
    else:
        history['–û—Ü–µ–Ω–∫–∞'] = history['–û—Ü–µ–Ω–∫–∞'].apply(lambda x: x if pd.notna(x) else "‚Äî")

    history = history[(history['–û—Ü–µ–Ω–∫–∞'].apply(lambda x: min_rating <= x <= max_rating if isinstance(x, (int, float)) else not show_only_rated))]

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    history = history.sort_values(['–î–∞—Ç–∞', '–ö–∞—Ç–µ–≥–æ—Ä–∏—è'], ascending=[False, True])
    history['–î–∞—Ç–∞'] = history['–î–∞—Ç–∞'].dt.strftime('%d.%m.%Y %H:%M')
    history['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'] = history['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'].apply(
        lambda x: f"{float(x) * 100:.1f}%" if pd.notnull(x) else "‚Äî"
    )

    # === –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø ===
    with st.expander("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º**")
            fig_cat = px.pie(history, names='–ö–∞—Ç–µ–≥–æ—Ä–∏—è')
            st.plotly_chart(fig_cat, use_container_width=True)
        
        with col2:
            st.markdown("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –º–æ–¥–µ–ª—è–º**")
            fig_model = px.pie(history, names='–ú–æ–¥–µ–ª—å')
            st.plotly_chart(fig_model, use_container_width=True)
        
        # –ì—Ä–∞—Ñ–∏–∫ –æ—Ü–µ–Ω–æ–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏)
        if not history[history['–û—Ü–µ–Ω–∫–∞'] != "‚Äî"].empty:
            st.markdown("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫**")
            fig_rating = px.histogram(history[history['–û—Ü–µ–Ω–∫–∞'] != "‚Äî"], x='–û—Ü–µ–Ω–∫–∞', nbins=5)
            st.plotly_chart(fig_rating, use_container_width=True)

    # === –ü–ê–ì–ò–ù–ê–¶–ò–Ø ===
    ITEMS_PER_PAGE = 50
    total_records = len(history)

    if total_records > ITEMS_PER_PAGE:
        total_pages = (total_records // ITEMS_PER_PAGE) + (1 if total_records % ITEMS_PER_PAGE else 0)
        page = st.number_input(
            "–°—Ç—Ä–∞–Ω–∏—Ü–∞", 
            min_value=1, 
            max_value=total_pages, 
            value=1
        )
        start_idx = (page - 1) * ITEMS_PER_PAGE
        end_idx = min(start_idx + ITEMS_PER_PAGE, total_records)
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        paginated_history = history.iloc[start_idx:end_idx]
    else:
        paginated_history = history

    # === –¢–ê–ë–õ–ò–¶–ê –° –î–ê–ù–ù–´–ú–ò ===
    columns_to_show = ['–î–æ–∫—É–º–µ–Ω—Ç', '–ú–æ–¥–µ–ª—å', '–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å', '–î–∞—Ç–∞', '–û—Ü–µ–Ω–∫–∞', '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π']

    st.dataframe(
        paginated_history[columns_to_show],
        column_config={
            "–î–∞—Ç–∞": st.column_config.TextColumn("–î–∞—Ç–∞"),
            "–î–æ–∫—É–º–µ–Ω—Ç": "–î–æ–∫—É–º–µ–Ω—Ç",
            "–ú–æ–¥–µ–ª—å": "–ú–æ–¥–µ–ª—å",
            "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": "–ö–∞—Ç–µ–≥–æ—Ä–∏—è",
            "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å": st.column_config.TextColumn("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"),
            "–û—Ü–µ–Ω–∫–∞": st.column_config.NumberColumn("–û—Ü–µ–Ω–∫–∞", format="%d"),
            "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π": "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"
        },
        hide_index=True,
        use_container_width=True,
        height=600
    )

    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–ø–∏—Å—è—Ö –ü–û–î —Ç–∞–±–ª–∏—Ü–µ–π
    if total_records > ITEMS_PER_PAGE:
        st.caption(f"–ü–æ–∫–∞–∑–∞–Ω—ã –∑–∞–ø–∏—Å–∏ {start_idx + 1}-{end_idx} –∏–∑ {total_records}")
    else:
        st.caption(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total_records}")