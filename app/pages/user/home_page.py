import streamlit as st
from datetime import datetime, timedelta
from utils.ml_utils import MODELS, classify_document
import time


# –ë–∞–∑–æ–≤–æ–µ –æ–∫–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º
def user_page(vectorizer):
    # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
    MAX_FREE_CLASSIFICATIONS = 3
    SESSION_KEY = "doc_classification_limit"
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
    if 'classification_result' not in st.session_state:
        st.session_state.classification_result = None
    if 'processing' not in st.session_state:
        st.session_state.processing = None
    if 'show_text' not in st.session_state:
        st.session_state.show_text = False

    # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞–º–∏
    def get_limit_data():
        if SESSION_KEY not in st.session_state:
            reset_time = datetime.now() + timedelta(days=1)
            st.session_state[SESSION_KEY] = {
                'used': 0,
                'reset_time': reset_time.timestamp()
            }
        return st.session_state[SESSION_KEY]
    
    limit_data = get_limit_data()
    remaining = MAX_FREE_CLASSIFICATIONS - limit_data['used']
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–±—Ä–æ—Å–∞ –ª–∏–º–∏—Ç–∞
    if time.time() > limit_data['reset_time']:
        limit_data['used'] = 0
        limit_data['reset_time'] = (datetime.now() + timedelta(days=1)).timestamp()
    
    # --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –∫–Ω–æ–ø–∫–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
    st.title("–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    # –ë–ª–æ–∫ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –∫–Ω–æ–ø–∫–∏)
    auth_cols = st.columns(2)  # –¢–µ–ø–µ—Ä—å —Ç–æ–ª—å–∫–æ 2 –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∫–Ω–æ–ø–æ–∫
    with auth_cols[0]:
        if st.button("üîë –í–æ–π—Ç–∏", key="login_btn", use_container_width=True):
            st.session_state.route = "login"
            st.rerun()
    with auth_cols[1]:
        if st.button("üìù –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è", key="register_btn", use_container_width=True):
            st.session_state.route = "register"
            st.rerun()
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ—Å—Ç—É–ø–Ω–æ–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–µ
    st.info("üîí –ü–æ–ª–Ω—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª (–≤–∫–ª—é—á–∞—è –æ–±—Ä–∞–±–æ—Ç–∫—É –∞—Ä—Ö–∏–≤–æ–≤) –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ—Å–ª–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏")
    
    # –°–æ–∑–¥–∞–µ–º placeholder –¥–ª—è —Å—á–µ—Ç—á–∏–∫–∞, —á—Ç–æ–±—ã –æ–±–Ω–æ–≤–ª—è—Ç—å –µ–≥–æ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏
    counter_placeholder = st.empty()
    if remaining <= 0:
        counter_placeholder.warning(f"‚ö†Ô∏è –í—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –≤—Å–µ {MAX_FREE_CLASSIFICATIONS} –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫")
        st.stop()
    else:
        counter_placeholder.info(f"üîÑ –û—Å—Ç–∞–ª–æ—Å—å –ø–æ–ø—ã—Ç–æ–∫: {remaining} –∏–∑ {MAX_FREE_CLASSIFICATIONS}")
    
    # –ë–ª–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    st.markdown("### üìÑ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    
    model_name = st.selectbox(
        "üß† –ú–æ–¥–µ–ª—å", 
        list(MODELS.keys()), 
        key="client_model"
    )
    
    uploaded_file = st.file_uploader(
        "üìé –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª", 
        type=["txt", "pdf", "docx"], 
        key="client_upload"
    )
    
    # –ö–Ω–æ–ø–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ø–æ–ª–Ω–∞—è —à–∏—Ä–∏–Ω–∞)
    if uploaded_file and st.button(
        "üöÄ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å", 
        key="client_classify",
        use_container_width=True
    ):
        if limit_data['used'] >= MAX_FREE_CLASSIFICATIONS:
            st.error("–õ–∏–º–∏—Ç –∏—Å—á–µ—Ä–ø–∞–Ω")
            st.stop()
        
        with st.spinner("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç..."):
            try:
                prediction, confidence, preview, wc, lang = classify_document(
                    uploaded_file, 
                    model_name, 
                    vectorizer
                )
                
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π —Å—Ä–∞–∑—É
                limit_data['used'] += 1
                remaining = MAX_FREE_CLASSIFICATIONS - limit_data['used']
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ
                if remaining <= 0:
                    counter_placeholder.warning(f"‚ö†Ô∏è –í—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –≤—Å–µ {MAX_FREE_CLASSIFICATIONS} –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫")
                else:
                    counter_placeholder.info(f"üîÑ –û—Å—Ç–∞–ª–æ—Å—å –ø–æ–ø—ã—Ç–æ–∫: {remaining} –∏–∑ {MAX_FREE_CLASSIFICATIONS}")
                
                # –§—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤
                def translate_class(pred):
                    class_map = {
                        "Order": "–ü—Ä–∏–∫–∞–∑",
                        "Ordinance": "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
                        "Letters": "–ü–∏—Å—å–º–æ",
                        "Miscellaneous": "–û–±—â–µ–µ",
                        # –î–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
                        0: "–ü—Ä–∏–∫–∞–∑",
                        1: "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
                        2: "–ü–∏—Å—å–º–æ",
                        3: "–û–±—â–µ–µ"
                    }
                    return class_map.get(pred, str(pred))
                
                if prediction is not None:
                    # –ü–æ–ª—É—á–∞–µ–º —Ä—É—Å—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞
                    russian_class = translate_class(prediction)
                    
                    if model_name == "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è":
                        st.success(f"‚úÖ –ö–ª–∞—Å—Å: **{russian_class}**")
                    else:
                        confidence_str = f"{confidence:.2%}" if confidence is not None else "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞"
                        st.success(f"‚úÖ –ö–ª–∞—Å—Å: **{russian_class}** (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: **{confidence_str}**)")
                    
                    st.caption(f"üåê –Ø–∑—ã–∫: **{lang}** &nbsp;&nbsp;|&nbsp;&nbsp;üìè –ö–æ–ª-–≤–æ —Å–ª–æ–≤: **{wc}**")
                    
                    with st.expander("üìÑ –ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞"):
                        st.text(preview)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —Ä—É—Å—Å–∫–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∫–ª–∞—Å—Å–∞
                    st.session_state.classification_result = {
                        'prediction': russian_class,
                        'confidence': confidence,
                        'text': preview,
                        'words': wc,
                        'lang': lang
                    }
                else:
                    st.error("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç")
                    
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞: {str(e)}")